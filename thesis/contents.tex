% What should the title be?
% Novelty Detection for Visual Indoor Categorization
% Novelty Detection on Semantic Representations.


\chapter{Introduction}
% Introduce:
%  Mobile Robotics, A.I.
%  Interaction with Humans
%  Need for concepts/semantic information
%  Dynamic human environment
%  Non-feasibility of hard-coded concepts
%  Requirements to detect novelty and handle it.
For a long time humanity has fantasized that one day robots will walk among us.
They will move and be able to interact with us. Understand our concepts and
be able to reason.

They need to possess ability to adapt to situations as its infeasible to rely
on extensive man-work to tag objects, map space and code all the aspects that
make up our human-reality.

% == Introduce the need of semantic representations ==
%
% There is a lot of low-level methods (or specific knowledge to robots)
% But the creation of semantic representations allow to bridge that low-level
% sensing with high-level concepts that facilitate several high-level Tasks.


% Importance of mapping and localization in a robot as well as reasoning on
% properties of each space.
% Humans give labels to space that characterized the properties and activities
% expected to be performed on them.
% Such information is of great interest to be structured and organized in such
% a way reasoning and planning can be implemented.
%
% It also holds an important role in long-term planning and stability as it
% hides the space-time local details and allows to focus on high-level thinking.

% Deal with uncertainty -> need for probabilistic models.
% Deal with semantic    -> need of structured models such as graphical models.


Example of what kind of an high-level thinking on space and its semantics can
provide: Get me a beer/milk concept.

% == Reasoning about need for Novelty Detection ==
%
% Dynamic environment (inability to know the environment or even to be possible
% to map all semantic concepts to interact with humans).
%
% Knowledge-Awareness (knowing what we know... And detecting novel cases)
% Identify gaps in the semantic knowledge.
% Automatic detection and learning of novel concepts.
%
% Increase robustness
% Self-Extending
%


\section{Problem and Goals}
% Extend a probabilistic graphical modelling framework with capabilities to
% detect novelty.
% Both in terms of novel classes as of novel structure.
%
Given a probabilistic structure representing the sensed conceptual knowledge
obtained by the agent develop methods able to detect novelty present
either on new semantic concepts (new classes) or even on structure that was
previously unknown.


% Yeah thats what you call dream :P
In an extreme ideal case the agent should be able to go from zero-knowledge to
understanding presence of certain objects (as generators of a set of sensed
sensed properties grouped locally), understand areas within rooms (sink-area on
on a kitchen), rooms as separated by doors, and understand environments such
as office, home, warehouse, spaceship.


For that the probabilistic semantic representation presented by
\cite{andrzej2011phd} is used.

% If everything goes fine... 2 of the "Future Directions" proposed are 
% Novelty Detection and Learning of Novel Concepts:
%  Identify Gaps in Spatial and Semantic Knowledge -> Addressed
%  Performing learning of new concepts -> Outside Scope / No Time
%
% Using Properties for Space Segmentation
%  If we move on detecting novel structures on the graph we are addressing this
%  issue.



\section{Thesis Outline}
The rest of this thesis is structured as follows:

\autoref{chap:background} introduces background concepts for understanding the
presented thesis. In particular \autoref{sec:graphical-models} introduces
\emph{probabilistic graphical models} that lay the base modelling tool for
the used structured semantic representation.

\autoref{chap:semantic-mapping} describes the system proposed by
\cite{andrzej}. In special it introduces the \emph{conceptual map} of the system
that is responsible for the creation of the \emph{probabilistic semantic
representation} that this thesis aims at improving by developing methods with
the capability to identify knowledge gaps.

\autoref{chap:novelty-intro} introduces novelty detection under a
statistical view point and how to interpret it as a threshold function.
A simple approach on how to perform novelty on very simple graphs
is given together with some results on the impact of using semi-supervised
novelty detection to improve the system performance.

\autoref{chap:novelty} presents the developed techniques developed to identify
novelty on the semantic representation.

\autoref{chap:conclusions} draws conclusions on the developed work and presents
interesting directions for future works.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{background}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Semantic Mapping}\label{chap:semantic-mapping}

% Advantages of Multi-modal approaches
% 

\section{Dora Architecture Overview}
\subsection{System organization}
\subsubsection{Sensory Layer}
\subsubsection{Categorical Layer}
\subsubsection{Place Layer}
\subsubsection{Conceptual Layer}

\section{Features}
\section{Conceptual Knowledge}
\section{Conceptual Map}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{novelty-intro}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Novelty Detection on Semantic Representations}\label{chap:novelty}
The semantic mapping representation presented in \autoref{chap:semantic-mapping}
permits the agent to understand and reason over the human semantic concepts of
space. By using semantic data not only it eases the process of communicating 
but also reduces complexity and allows easy implementation of high-level
decisions.
Due to the nature of semantic data, variables have to be considered
uncertain. For that reason the whole semantic representation is instantiated
as a probabilistic structure: a \emph{conceptual map}. 

Although the conceptual map permits uncertain reasoning it does not incorporates
any detection mechanism for identifying or copping with knowledge gaps.
This means the system needs to consider the knowledge absolute and is not
able to detect by itself that some of it does not correctly describes reality. 

The main goal of this thesis is to address this issue by developing methods
able to detect both novel classes and novel structures on the semantic
representation. Allowing a more efficient behaviour when performing on unknown
and new environments. It is an important milestone on developing of high-level
knowledge and active learning.


\section{Detecting New Classes}
This section focus on detecting a novel class on single variable of the
conceptual map. As seen before on \autoref{chap:novelty-intro},
novelty detection can be done by implementing a threshold on
$P(x|\overline{novel})/P(x)$.
In order to correctly measure novelty on a single variable both
conditional and unconditional probabilities need to be coherently defined:


The conceptual layer build a \emph{probabilistic graphical model} $G$ that
represents the distribution of the sensed features assuming that both the known
structure and the known classes hold in the sample.
For that reason the correct approach is to use $P_G(x)$ as an approximation for
$P(x|\overline{novel})$.

Assume now that everything the conceptual layer knows holds true except the
class of a single variable $a$, which the system possess no information on. 
In that case the correct approach is to replace the factors associated with
that variable with factors representing the prior-information the system has on
the unconditional distribution of those factors.
In case no information is available this means replace by a uniform factor\footnote{In case the
unconditional factors are uniform, this is the same as omitting the factors
from the graph structure.} accordingly to the principle of maximum entropy.
Note that in case some information was known on the prior distribution, the
correct approach is to replace the factors by the distributions that have that
information in account (as is the case in \autoref{sec:unlabelled-data}).
Let this new factor graph with unconditional factors $\phi_u$ on the variable
$a$ be $U$. $P(x)$ is then approximated by $P_U(x)$.

\begin{figure}[h]
\centering
\subfloat[Factor graph modelling the probability distribution in the case both
          the variables types and graph structure hold true.]{
          Hello get a graph here.}
\qquad\qquad
\subfloat[Factor graph modelling the probability distribution in the case
          where only variable $a$ does not conforms to any class the system
          has learned before.]{
          Hello get a graph here.}

\caption{\label{fig:nd-single-variable}Graphs used to model novelty detection on
         a class of a single variable $a$, assuming all the other variables
         classes and graph structure are correctly modelled by the agent
         knowledge.}
\end{figure}


\section{Copping with Multiple Novel Variables}
On the previous section it was shown how to detect a novel class on a variable
assuming that the rest of the graph variables and structure is correctly modeled
by the agent knowledge.
But the test to detect a given variable $a$ is novel requires both a structure
$G$ representing the case where no knowledge gaps exist and a structure $U$
representing the case where $a$ was identified as a novel class.

It may be tempting to use a deterministic approach on the system such as:
when the agent determines a variable to have a novel class, it marks it as novel
and proceeds.

Such an approach would no longer be optimal and not be dynamic
executes on a new
structure $U$ 
of the semantic structure it does not allows the
semantic structure to be used

In this section we show how to handle novelty in several variables
in simultaneous.\footnote{I am almost sure the math here will work out the
way I think}

\subsection{Handling novelty signals from the low-level classifiers}
Explain how to handle novelty signals from low-level classifiers, now that we
have a model with the ability to still reason when several variables can be
novel.

\section{Detecting New Structure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusions and Future Work}\label{chap:conclusions}
\section{Future Work}

