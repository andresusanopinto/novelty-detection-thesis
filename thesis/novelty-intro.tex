\chapter{Novelty Detection}\label{chap:novelty-intro}

This chapter presents the main work of this thesis: a method to augment the conceptual
map with novelty detection capabilities.

The chapter starts by providing the reader with a brief overview on novelty detection
techniques and related works. Then it shows that an optimal novelty detection system
can be implemented by thresholding on a order-relation defined over the inputs.
And that an equivalent order-relation can be imposed by a ratio between
conditional and unconditional probabilities.
Some discussion on how to interpret the meaning of those factors is also
presented.

At last a practical example using semantic data and probabilistic graphical
models is presented: it shows how to use the introduced ratio to obtain a
novelty detection system and analyses the performance impact by increasing
the amount of sensed data and by using an approximation on the unconditional
probability.


\section{Novelty Detection Review and Related Work}
Novelty detection, also known as outlier or anomaly detection, is a
classification problem related to identification of new or unknown data
patterns that the system is not aware of~\cite{markou2003novelty}.

The ability to identify novel cases is crucial in any autonomous system
that is deployed to unknown or to uncontrolled environments, as it gives the
system the ability to detect that something is not conforming to its knowledge and
therefore should be treated with caution.
It has several applications such as fault detection~\cite{tarassenko1999novelty},
intrusion detection~\cite{fan2001using},
detection of masses in mammograms~\cite{tarassenko1995novelty} or detection of
novel and useful documents~\cite{zhang2002novelty}.

Any normal classification application is also a good candidate for extending
with novelty detection, as the results for samples the system has not been
trained on can be unreliable~\cite{devarakota2008reliability}.
e.g.\ applied to digit-recognition~\cite{tax1998outlier}
or to detection of novel inputs on a neural network~\cite{bishop1994novelty}.

It is in the nature of unknown environments and in the infeasibility of
the system to acquire examples of all possible classes where the complexity of
novelty detection lies: it is only possible to obtain samples representing positives
examples of known cases and the lack of negative examples renders normal
classification methods unusable.
In order to become practical in real world applications, novelty detection
methods have to overcome a series of obstacles:
be able to generalize while still detecting novelty,
be resistant to noisy features,
ability to scale in feature dimension,
deal with multiple classes and performing detection efficiently as many
autonomous systems require real-time or close to real-time performance.

\subsection{Review of Novelty Detection Methods}
A common approach is to use density estimation and use the expected probability
of a sample to classify the sample as novel. Examples of such techniques are
Gaussian Mixture Models and Parzen-window estimators. In order to be effective,
those rely on data as close as possible to the input features and use
dimensionality\hyp{}reduction techniques such as \gls{PCA} to make density
estimation feasible. Note that as dimension increases an exponential number
of data samples would be required to approach the density with the same quality.

\cite{bishop1994novelty} uses that approach by employing a Parzen-window to
estimate the density of the training data on a given input fed into a
neural-network. Using the calculated density, they detect samples
that differ from the training data and consider their neural-network output
to be unreliable as the samples are distinct from what the network was trained
with.

A slightly different approach is applied in case of by one-class \gls{SVM} approaches that
try to distinguish novelty by separating the training set from all the other
points in the input space. They try to achieve that by enclosing the training
set by some structure (e.g.\ an hyper-sphere)~\cite{bennett2000support}.
Those approaches have been made in line with Vapnik principle of not solving
something hard. As although having access to a perfect probability distribution
of the input would solve the problem, creating such a function is harder than
simply creating a boundary between known data and novel data
\cite{scholkopf2000support}.

Error reconstruction methods have also been used for novelty detection.
They use the assumption that the class to be defined lies on a manifold embedded
into a sample space of higher dimensionality. By using dimensionality\hyp{}reduction
techniques, a manifold is defined and the distance between the manifold and the new sample
is calculated. One of the most common methods used for that purpose is
\gls{K-PCA}~\cite{scholkopf1997kernel}, which uses the kernel-trick to extend
\gls{PCA} and perform a nonlinear dimensionality reduction of the input.
This technique has been successfully used for novelty detection in \cite{Hoffmann2007863}.

\cite{japkowicz1995novelty} also follows a similar approach: \emph{Redundancy
Compression and Non-Redundancy Differentiation} which is a process believed
to happen in the hippocampus. They introduce an auto-encoder
that learns to encode a sample on a considerable smaller description and later reconstructs
the original sample from this smaller description. Their suggested system
learns how to discard and compress redundant information while still be able to recover
the original sample. By training it with samples from a given class, it
is expected that it will badly reconstruct a sample from a different one.

\cite{ranganathan2010pliss} presents a system able to perform place recognition
and classification from visual clues. It is able to perform segmentation by
exploiting time-coherency on video information. The approach is particularly
interesting by its ability of keeping a fully probabilistic distribution of
the place classification and segmentation. This is, the system never performs
a deterministic decision that impacts any future result, allowing it to adjust
the segmentation and place classification as more data becomes available.
The system is also able to detect novel instances and methods how to adapt it
to run on a constant amount of memory and computation are presented.

\cite{boutell2006factor} presents a method to perform scene-classification
from low-level region detectors using probabilistic graphical models.
The information obtained by the region detectors is exploited together with the
spatial relations between on the higher level scene-classification task.
A presented scheme using only pairwise relations between regions is show to
have better performance than the correct approach of modelling all regions connectivity
with a large single-factor as the pairwise relations can be
approximated with modest amounts of training data, where the single-factor
demands an impractical amount of training data.
No approach is made on it at novelty detection either of regions or scene
categories. 


\section{Novelty Detection by Thresholding}
\label{sec:threshold}
The objective of a novelty detection system is to classify a given sample $x$ as
either \emph{known}: $x$ being generated by a known class to the system, or \emph{novel}:
$x$ generated by a class unknown for the system.
Based on the ground\hyp{}truth of a sample four cases are possible:

\begin{description}
\item[true positive]  - when a system correctly   flags a sample of an unknown class as \emph{novel}.
\item[false positive] - when a system incorrectly flags a sample of a known class as \emph{novel}.
\item[true negative]  - when a system correctly   flags a sample of a known class as \emph{known}.
\item[false negative] - when a system incorrectly flags a sample of an unknown class as \emph{known}.
\end{description}

Due to noisy data, unstable features and lack of information it is impossible to develop
a method able to exactly guess the correct classification of a sample.
By modelling the outcomes with probabilities it becomes possible to handle the uncertainty
associated with each decision.
The notation $P(novel|x)$ will be used to denote the probability that the sample $x$ is in fact a
sample of an unknown class. $P(x)$ will denote the probability that sample $x$ is given to the
system to be classified. $\overline{novel}$ is also defined in such a way that
$P(\overline{novel}|x)$ measures the probability that a decision on classifying $x$ as novel is
wrong.

Additionally a decision on the novelty of a sample $x$ performed by a deterministic system
will be fully determined by the sample itself.
Which implies that any deterministic novelty detection system can be uniquely determined by the set $N$
of samples that are accepted by the classifier as \emph{novel}.
This way it is possible to define the probability of a true positive and false positive event for any
deterministic novelty detector with the following equations:

\begin{eqnarray}
P(\text{true positive})  &=& \sum_{x \in N}{P(novel|x)P(x)} \\
P(\text{false positive}) &=& \sum_{x \in N}{P(\overline{novel}|x)P(x})
\end{eqnarray}

Note that since probability functions are non-negative, it is impossible to decrease either the
true positive or the false positive probability by using a set $N' \supset N$.
This describes the base of the \emph{error and rejection tradeoff}~\cite{chow1970optimum}, which
states that a system aiming at increasing the true-positive probability will eventually increase its
false-positive error.
The true positive probability can be described as the interest in detecting as much
as possible the novel classes and the false positive probability the interest
in not incurring in too many errors.
By fixating one of those it is possible to define a novelty detection
system that achieves the maximum or minimum of the other.

This way an optimal detector can be formulated by achieving the maximum true-positive
probability without its false-positive probability increase beyond a given limit.
This is equivalent to a \emph{continuous knapsack problem} which allows a greedy
solution by sorting the items with a value per weight function.
In the case of detection system that can be defined as:

\begin{eqnarray}
value(x)  &=& P(\text{true positive}|x) \\
weight(x) &=& P(\text{false positive}|x) \\
cost(x)   &=& value(x)/cost(x) \\
          &=& \frac{P(novel|x)P(x)}{P(\overline{novel}|x)P(x)}
\end{eqnarray}

Therefore a novelty system before classifying a sample $a$ as novel should (greedily)
classify any sample $b$ with a small cost as that would achieve
an higher true positive probability given a fixed false positive one.

\begin{equation}
\label{eq:knapsack}
\frac{P(novel|b)}{P(\overline{novel}|b)} < \frac{P(novel|a)}{P(\overline{novel}|a)}
\end{equation}

This relation between $a$ and $b$ can further be simplified into:

\begin{equation}
P(\overline{novel}|b) < P(\overline{novel}|a)
\end{equation}


Based on this, it can be said that an optimal novelty detection system is
interested in defining an order relation on all the possible inputs equivalent
to the order defined by the function: $P(\overline{novel}|x)$.
And any optimal detector can be described by the largest $P(\overline{novel}|x)$
accepted by it. Which is seen as threshold.


\section{Conditional and Unconditional Probability Ratio}

On the previous section it was shown that an optimal novelty detector can be
implemented with a threshold on top of the order-relation defined by
$P(\overline{novel}|x)$ over $x$. Performing some manipulations with
Bayes theorem and assuming a constant $P(\overline{novel})$ a more usable
form can be attained:

\begin{equation}
\label{eq:novelty-ratio}
          P(\overline{novel}|x)
  =       \frac{P(x|\overline{novel}) P(\overline{novel})}{P(x)}
  \propto \frac{P(x|\overline{novel})}{P(x)}
\end{equation}

Since there is only interest in maintaining the same order-relation as
$P(\overline{novel}|x)$ any constant factor can be dropped.
Leaving a ratio between a \emph{conditional} and
\emph{unconditional probability} suitable for implementing novelty detection
by thresholding.


\subsection{Conditional Probability}
The conditional probability $P(x|\overline{novel})$ describes the distribution
of the samples given that they are generated by a known class.
In case the labelled data available for the agent to learn a concept comes from
the same distribution where the system will run the correct approach is to use it
as prior-information for modelling the conditional probability.

Note that it is important for the labelled data to be a filtered version
of the underlying world distribution (with all classes) that does not contains
any bias.
Otherwise that bias will lead to incorrect modelling the conditional probability
and a subsequent wrong ordering of the sample space.

\subsection{Unconditional Probability}
The unconditional probability $P(x)$ plays an important role on obtaining a
correct order relation for performing novelty detection.
It serves as a normalizing component that allows the system to figure out
whether a given sample conditional probability arises from it belonging to
the known concept or from the likelihood of being sampled.

On lack of any information about the unconditional probability and conforming to
the principle of maximum entropy (\autoref{sec:max-entropy}) a uniform
distribution must be chosen.
Though by using unlabelled data it becomes possible to obtain extra information
and achieve a better approximation.


%\subsection{Novelty Detection on a Variable Set of Features}
Note also that often novelty detection is applied on a fixed set of features
together with an assumption of a uniform unconditional probability.
On those cases $P(x)$ becomes a constant and therefore a novelty threshold
can be directly applied on $P(x|\overline{novel})$ as is the case in \cite{bishop1994novelty}.
But in the case where the set of features $x$ is variable it cannot be
discarded. There $P(x)$ plays a role in levering all the conditional
probabilities on different sets of variables into the same measure units
such that a threshold can be implemented.

\subsection{Assumption on a constant $P(novel)$}
The ratio between the conditional and unconditional probabilities of the sensed variables
is only directly applicable to novelty detection under the assumption of a constant $P(novel)$.

All the literature focus on novelty detection within a fixed scenario, where the set of variables
used to model the distribution is fixed and defined at the moment the threshold is trained.
Due to that, they can drop a constant $P(novel)$ and never need to directly or indirectly calculate
it.
To the best of the author knowledge there has not been studies on how to approximate it on dynamic
sets and structures of sensed variables, and so a strong assumption on being constant through all
the possible scenarios is used to allow dropping the factor.

This assumption was considered questionable on whether it holds on a realistic scenario,
and for that a sampling scheme able to comply with it is now presented as well an unbiased sampling
scheme. A method to generate samples that match this \emph{criterium} of having a constant $P(novel)$ can be:

\begin{algorithm}[Draw samples with equal $P(novel)$]
\begin{enumerate}
\item Sample a graph structure $G$ (where variable $a$ can be any of the known or unknown classes)
\item Decide novelty of $a$.
\item Sample the remaining variables according to distribution $P_G(x|a)$.
\end{enumerate}
\end{algorithm}

According to this sampling algorithm, given any structure the probability of
variable $a$ being novel is constant. This is somehow unexpected as it means
the sampling method is biased to adjust the real distribution $G$ such that
exactly a constant percentage of drawn samples are novel.

Alternative, the sampling method described below is considered more correct as
it introduces no bias on the distribution $G$ describing the real distribution
and classes of $a$:
\begin{algorithm}[Draw samples with equal $P(novel)$]
\begin{enumerate}
\item Sample a graph structure $G$ (where variable $a$ can be any of the known or unknown classes)
\item Sample variables $x$ according to distribution $P_G(x)$.
\end{enumerate}
\end{algorithm}

Due to the highly bias needed to drawn a constant amount of novel sampes from any structure, the
author defends this assumption to be very strong and points that future work should avoid.

 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Novelty Detection on the Conceptual Map}

This section presents now how to use graphical models produced by the conceptual map and the
novelty detection concepts introduced earlier on this chapter in order to detect room categories the
system is not aware of.

For that both models to approximate both the conditional and unconditional probability need to
be defined and then the ratio between them used to define a function over which a threshold
implements a novelty detection system.

\subsection{Approximating the Conditional Probability}
The actual semantic mapping of the environment happens using the \emph{conceptual map}
introduced on \autoref{sec:conceptual-map}. During it the agent instantiates a
\emph{chain graph} to model distribution of the sensed variables according to the known
concepts and categories introduced as hidden variables on the graph. Using that graphical model
the system is able to propagate and find the most likely configuration of the represented
variables. For instance, the semantic category of a specific room is modelled as an hidden variable
with states representing the semantic values, by calculating probabilities on that variable the
system finds its belief on the room belonging to a specific category.

Since the graphical model produced by the conceptual map tries to model the distribution of
variables assuming the knowledge of the agent holds true, it represents a method to model
$P(x|known)$ since it allows to calculate the density probability that the set of features $x$ is
sensed given that all the variables and graph structure, including the category of
a specific room $a$ are correctly modelled by the agent knowledge.
This way the distribution modelled by a factor graph equivalent to the chain-graph used by
the conceptual map can be used as an approximation for the conditional probability of $x$.

\begin{figure}[h]
\centering
\begin{tikzpicture}
  \node [matrix,matrix anchor=mid, column sep=15pt, row sep=10pt,ampersand replacement=\&] {
    \& \& \node (room3) [latent] {}; \& \\
    \& \& \& \\
    \&
    \node (room1) [latent] {$a$}; \& \&
    \node (room2) [latent] {}; \\
    \& \& \& \\
    \node (shape1f) [factor] {}; \&
    \node (appearance1f) [factor] {}; \&
    \node (object1f) [factor] {}; \&
    \node (factor2) [factor] {}; \\
    \node (shape1l) [obs] {$S_p$}; \&
    \node (appearance1l) [obs] {$A_p$}; \&
    \node (object1l) [obs] {$O_p$}; \&
    \node (prop2) [obs] {$X_p$}; \\
  };

  \draw [-] (room1) -- (shape1f) -- (shape1l);
  \draw [-] (room1) -- (appearance1f) -- (appearance1l);
  \draw [-] (room1) -- (object1f) -- (object1l);
  \draw [-] (room2) -- (factor2) -- (prop2);

  \draw [-] (room1) -- (room2) node (r12f) [midway,factor] {};
  \draw [-] (room1) -- (room3) node (r13f) [midway,factor] {};
  \draw [-] (room2) -- (room3) node (r23f) [midway,factor] {};

  \begin{pgfonlayer}{background}
    \plate{places1}{(shape1f)(shape1l)(object1l)}{$\forall p \in places(room1)$}{};
    \plate{places2}{(factor2)(prop2)}{$\dots$}{};
  \end{pgfonlayer}
\end{tikzpicture}

\caption{Factor graph modelling the conditional probability distribution, case where the
         room category of room $a$ is known by the system.}
\end{figure}


\subsection{Approximating the Unconditional Probability}

With no knowledge on the unconditional probability the correct approach is to
assume a uniform distribution (\autoref{sec:max-entropy}), which can be modelled by a
factor graph without any factors: \autoref{fig:uniform-graph}.

\begin{figure}[h]
\centering
\begin{tikzpicture}
  \node [matrix,matrix anchor=mid, column sep=20pt, row sep=10pt,ampersand replacement=\&] {
    \node (x1) [obs] {$S_1$}; \&
    \node (x2) [obs] {$A_1$}; \&
    \node (x3) [obs] {$O_1$}; \&
    \node (xi) [] {\dots}; \&
    \node (xn) [obs] {$X_n$}; \\
  };
\end{tikzpicture}
\caption{\label{fig:uniform-graph}A factor graph modelling a uniform
         distribution over the sensed set of features $x$.}
\end{figure}

Thought, very often there is extra knowledge that can be obtained about the distribution
of the variables that helps to model the unconditional distribution. With that, more accurate
models can be produced.
In this case, the system is interested in detecting only if a specific variable category is not
known. With that in mind, it was assumed that the graph structure is known and that an unknown
category can only influence variables by using the same structure as the known variables.
This way the structural information and all the other hidden variables the system is aware of
can be used to more accurately approximate the unconditional distribution.

\begin{figure}[h]
\centering
\subfloat[\label{fig:any-a}Since variable $a$ can be unknown, the agent does not has
knowledge on how to model the dashed relations.]{
\begin{tikzpicture}
  \node [matrix,matrix anchor=mid, column sep=15pt, row sep=10pt,ampersand replacement=\&] {
    \&
    \&
    \node (room3) [latent] {}; \& \\
    \& \& \& \\
    \&
    \node (room1) [latent,dashed] {$a$}; \& \&
    \node (room2) [latent] {}; \\
    \& \& \& \\
    \nofactor {shape1f}{}{} {right=0pt}; \&
    \nofactor {appearance1f}{} {} {right=0pt}; \&
    \nofactor {object1f}{} {} {right=0pt}; \&
    \node (factor2) [factor] {}; \\
    \node (shape1l) [obs] {$S_p$}; \&
    \node (appearance1l) [obs] {$A_p$}; \&
    \node (object1l) [obs] {$O_p$}; \&
    \node (prop2) [obs] {$X_p$}; \\
  };
  \draw [-] (shape1f) -- (shape1l);
  \draw [-] (appearance1f) -- (appearance1l);
  \draw [-] (object1f) -- (object1l);
  \draw [-] (room2) -- (factor2) -- (prop2);
  \draw [-,draw=none] (room1) -- (room2) node (r12f) [midway,factor] {};
  \draw [-,draw=none] (room1) -- (room3) node (r13f) [midway,factor] {};
  \draw [-] (room2) -- (room3) node (r23f) [midway,factor] {};
  \draw [-] (room2) -- (r12f);
  \draw [-] (room3) -- (r13f);

  \draw [-,dashed] (room1) -- (shape1f);
  \draw [-,dashed] (room1) -- (appearance1f);
  \draw [-,dashed] (room1) -- (object1f);
  \draw [-,dashed] (room1) -- (r12f);
  \draw [-,dashed] (room1) -- (r13f);

  \begin{pgfonlayer}{background}
    \plate{places1}{(shape1f)(shape1l)(object1l)}{$\forall p \in places(room1)$}{};
    \plate{places2}{(factor2)(prop2)}{$\dots$}{};
  \end{pgfonlayer}
\end{tikzpicture}
}
\qquad \qquad
\subfloat[Without knowledge on all states of $a$, all variables dependent on $a$ get directly
          dependent between each other, introducing a big single factor.]{
\begin{tikzpicture}
  \node [matrix,matrix anchor=mid, column sep=15pt, row sep=10pt,ampersand replacement=\&] {
    \& \& \node (room3) [latent] {}; \& \\
    \& \& \& \\
    \&
    \node (room1) [factor] {}; \& \&
    \node (room2) [latent] {}; \\
    \& \& \& \\
    \&
    \&
    \&
    \node (factor2) [factor] {}; \\
    \node (shape1l) [obs] {$S_p$}; \&
    \node (appearance1l) [obs] {$A_p$}; \&
    \node (object1l) [obs] {$O_p$}; \&
    \node (prop2) [obs] {$X_p$}; \\
  };

  \draw [-] (room1) -- (shape1l);
  \draw [-] (room1) -- (appearance1l);
  \draw [-] (room1) -- (object1l);
  \draw [-] (room2) -- (prop2);

  \draw [-] (room1) -- (room2);
  \draw [-] (room1) -- (room3);
  \draw [-] (room2) -- (room3) node (r23f) [midway,factor] {};

  \begin{pgfonlayer}{background}
    \plate{places1}{(shape1f)(shape1l)(object1l)}{$\forall p \in places(room1)$}{};
    \plate{places2}{(factor2)(prop2)}{$\dots$}{};
  \end{pgfonlayer}
\end{tikzpicture}
}
\caption{\label{fig:known-struct}Factor graph modelling distribution of sensed variables when variable $a$ can be unknown.}
\end{figure}

If the structure and all the other variables can be assumed to be correctly modelled by the
knowledge of the agent, then all variables that are directly dependent on $a$ become directly
dependent between them, introducing a single factor (\autoref{fig:known-struct}).
By approximating this factor the agent can then obtain a model for the unconditional probability.

In cases no other information is available the introduced factor can be considered uniform\footnote{Uniform factors do not influence the
distribution represented by the factor graph and so can be removed from the graph representation}
and dropped from the graph (see \autoref{fig:uniform-model}).
Nonetheless it may be the case that due the cost of labelling data, the agent does not has knowledge
on all the possible categories of $a$, but still has access to unlabelled data.
In that case unlabelled samples may be gathered and explored to achieve a better approximation of
the real distribution of variables.
Though the factor that needs to be approximated requires handling of all the connected variables
and enormous amounts of data may be needed to approximate it.

A simple approach can be performed by assuming the variables connected to the factor to be independent
but having a bias towards certain values. This approach is equivalent to connecting single factors
on each of variables and approximating those factors using unlabelled data as seen on \autoref{fig:independent-model}.


\begin{figure}[h]
\centering
\subfloat[\label{fig:uniform-model}Uniform Model]{
\begin{tikzpicture}
  \node [matrix,matrix anchor=mid, column sep=15pt, row sep=10pt,ampersand replacement=\&] {
    \& \& \node (room3) [latent] {}; \& \\
    \& \& \& \\
    \&
    \node (room1) [factor] {}; \& \&
    \node (room2) [latent] {}; \\
    \& \& \& \\
    \&
    \&
    \&
    \node (factor2) [factor] {}; \\
    \node (shape1l) [obs] {$S_p$}; \&
    \node (appearance1l) [obs] {$A_p$}; \&
    \node (object1l) [obs] {$O_p$}; \&
    \node (prop2) [obs] {$X_p$}; \\
  };

  \draw [-,dashed] (room1) -- (shape1l);
  \draw [-,dashed] (room1) -- (appearance1l);
  \draw [-,dashed] (room1) -- (object1l);
  \draw [-] (room2) -- (prop2);

  \draw [-,dashed] (room1) -- (room2);
  \draw [-,dashed] (room1) -- (room3);
  \draw [-] (room2) -- (room3) node (r23f) [midway,factor] {};
  \node (captroom1) [above=0pt of room1] {\footnotesize{U}};

  \begin{pgfonlayer}{background}
    \plate{places1}{(shape1f)(shape1l)(object1l)}{$\forall p \in places(room1)$}{};
    \plate{places2}{(factor2)(prop2)}{$\dots$}{};
  \end{pgfonlayer}
\end{tikzpicture}
}
\qquad
\subfloat[\label{fig:independent-model}Independent Model] {
\begin{tikzpicture}
  \node [matrix,matrix anchor=mid, column sep=15pt, row sep=10pt,ampersand replacement=\&] {
    \& \& \node (room3) [latent] {}; \& \\
    \& \& \& \\
    \&
    \node (room1) [latent,draw=none] {}; \& \&
    \node (room2) [latent] {}; \\
    \& \& \& \\
    \node (shape1f) [factor] {}; \&
    \node (appearance1f) [factor] {}; \&
    \node (object1f) [factor] {}; \&
    \node (factor2) [factor] {}; \\
    \node (shape1l) [obs] {$S_p$}; \&
    \node (appearance1l) [obs] {$A_p$}; \&
    \node (object1l) [obs] {$O_p$}; \&
    \node (prop2) [obs] {$X_p$}; \\
  };

  \draw [-] (shape1f) -- (shape1l);
  \draw [-] (appearance1f) -- (appearance1l);
  \draw [-] (object1f) -- (object1l);
  \draw [-] (room2) -- (factor2) -- (prop2);

  \draw [-,draw=none] (room1) -- (room2) node (r12f) [midway,factor] {};
  \draw [-,draw=none] (room1) -- (room3) node (r13f) [midway,factor] {};
  \draw [-] (room2) -- (room3) node (r23f) [midway,factor] {};
  \draw [-] (room2) -- (r12f);
  \draw [-] (room3) -- (r13f);

  \begin{pgfonlayer}{background}
    \plate{places1}{(shape1f)(shape1l)(object1l)}{$\forall p \in places(room1)$}{};
    \plate{places2}{(factor2)(prop2)}{$\dots$}{};
  \end{pgfonlayer}
\end{tikzpicture}
}

\caption{Factor graph modelling the conditional probability distribution, case where the
         room category of room $a$ is known by the system.}
\end{figure}
 

Other schemes may be tried to approximate the unconditional independent assuming that only
a specific variable is not necessarily known. For example modelling unconditional probability
with an hidden variable trained from the unlabelled data. Or by trying to split the single big
factor on factorizations of other factors.
Though the presented cases have interesting properties:

\begin{description}
\item[uniform model] - by assuming the factor to be uniform, it can be considered as not existent on
the graphical model.

\item[independent model] - due to the use of single connected factors, it can easily be trained from
                           unlabelled data. This helps the system to account for an existent bias on
                           each of the variables without allowing the system to overfit to the unlabelled
                           data.
\end{description}

\subsection{Threshold}
After defining a model for the conditional and unconditional distributions, a threshold can be applied
over the ratio of those.
Under the assumption of a constant $P(novel)$, defining a threshold over it leads to an optimal novelty
detector, as showed on \autoref{sec:threshold}.

If the training data does not contains any bias, by picking a threshold on the training data that achieves
a certain true-positive and false-positive rate, it is expected that on the real distribution such a system
will achieve the same performance.

Note however that the performance of the system is dependent on how well the models approximate the conditional
and unconditional distributions and so are dependent on how the graph structure is able to model the real distribution
and how well the training data allows the factors to be approximated.

\section{A Practical Example}
\label{sec:unlabelled-data}
In order to sum up the presented concepts on novelty detection with a threshold
function and exemplify how to use graphical models in the context of
multi-modality room classification a synthetic dataset was generated.
The dataset was kept simple by only modelling directly sensed features from a
room, skipping any structural knowledge or sensing model such as room
connectivity and extra hidden variables.

In this dataset a room $r$ is seen as an hidden-variable generator of a set of
features $X$ that are directly sensed by the agent.
All the sensed features $x$ are independent given the room category.
In whole there was 11 different room categories and 7 different feature types.
Each feature can be sensed more than once (e.g.\ room shape is extracted from 2D
laser scans in more than one position in the room), but all those sensed
instances are considered independent given the room category.

The room categories were chosen to mimic as close as possible the real features
and categories existing in reality (i.e.\ 1 person office, 2 person office,
hallway, robot lab, etc\dots). A table describing the used synthetic
distribution is given in \autoref{extra:synthetic-distribution}.

The objective then was to design a system that, although only trained with
labelled data from 5 of the 11 room categories, was able to detect novel
room categories.
For that 100 labelled samples for the 5 known categories were drawn and 1000 
unlabelled samples were drawn from all the room categories for learning the
unconditional probability distribution and measure effect of using unlabelled
data.

\begin{sidewaystable}[h]
\begin{center}
\scalebox{0.40}{\input{results/ontology-explain}}
\end{center}
\caption{\label{extra:synthetic-distribution}Distribution used on the synthetic experiment. Each column cell shows $P(feature|class)$}
\end{sidewaystable}


\subsection{Conditional Probability}
Using the labelled samples, 7 factors $\phi_X(r,x)$ were created, one for each
feature type, to represent the potential of sensing features $x$ of type $X$ on
a room of category $r$.

% TODO: discuss this with Andrzej
\begin{equation}
\phi_X(r,x) = \frac{\#(r,x)+C}{\sum_{i \in X}{\#(r,i)+C}}
\end{equation}

Where $\#(r,x)$ denotes the number of times a feature $x$ was sensed inside a
room category $r$ and $C$ is a smoothing parameter that accounts for fixing
the probabilities in case a given sample is never seen.
With those the probability of sensing a set of features $x$ on a room category
$r$ known for the agent can be modelled with a factor graph as illustrated on
\autoref{fig:simple-cond-graph}.

\begin{figure}[h]
\centering
\begin{tikzpicture}
  \node [matrix,matrix anchor=mid, column sep=20pt, row sep=10pt,ampersand replacement=\&] {
    \& \& \node (room) [latent] {$r$}; \& \& \\
    \& \& \& \& \\
    \node (f1) [factor] {}; \&
    \node (f2) [factor] {}; \&
    \node (f3) [factor] {}; \&
    \node (fi) [] {\dots}; \&
    \node (fn) [factor] {}; \\
    \node (x1) [obs] {$x_1$}; \&
    \node (x2) [obs] {$x_2$}; \&
    \node (x3) [obs] {$x_3$}; \&
    \node (xi) [] {\dots}; \&
    \node (xn) [obs] {$x_n$}; \\
  };
  \draw [-] (room) -- (f1) -- (x1);
  \draw [-] (room) -- (f2) -- (x2);
  \draw [-] (room) -- (f3) -- (x3);
  \draw [-] (room) -- (fi);
  \draw [-] (room) -- (fn) -- (xn);

  \node (captf1) [right=2pt of f1] {\footnotesize{$\phi_{X_1}$}};
  \node (captf2) [right=2pt of f2] {\footnotesize{$\phi_{X_2}$}};
  \node (captf3) [right=2pt of f3] {\footnotesize{$\phi_{X_3}$}};
  \node (captfn) [right=2pt of fn] {\footnotesize{$\phi_{X_n}$}};
\end{tikzpicture}
\caption{\label{fig:simple-cond-graph}A factor graph modelling the conditional
probability of sensing a set of features $x$ given that the room category $r$ is
one of the known classes.}
\end{figure}

\subsection{Unconditional Probability}
\label{sec:sample-uncond-prob}
With no knowledge on the unconditional probability the correct approach is to
assume a uniform distribution.
That is represented in factor graphs by a graph without any factors.

\begin{figure}[h]
\centering
\begin{tikzpicture}
  \node [matrix,matrix anchor=mid, column sep=20pt, row sep=10pt,ampersand replacement=\&] {
    \node (x1) [obs] {$x_1$}; \&
    \node (x2) [obs] {$x_2$}; \&
    \node (x3) [obs] {$x_3$}; \&
    \node (xi) [] {\dots}; \&
    \node (xn) [obs] {$x_n$}; \\
  };
\end{tikzpicture}
\caption{\label{fig:simple-uniform-graph}A factor graph modelling a uniform
         distribution over the sensed set of features $x$.}
\end{figure}

Very often there is extra knowledge that can be obtained about the distribution
of the variable that helps to model the unconditional distribution.
In this practical example the access to unlabelled data is explored as access to
it is common on applications in robotics.

Note that the sensed variables are dependent between each other when the room
category $r$ is not known. With that the correct approach would be to train a
factor that is able to correlate all the sensed variables as seen on
\autoref{fig:simple-all-dependent}.

\begin{figure}[h]
\centering
\begin{tikzpicture}
  \node [matrix,matrix anchor=mid, column sep=20pt, row sep=10pt,ampersand replacement=\&] {
    \& \& \node (fac) [factor] {}; \& \& \\
    \& \& \& \& \\
    \node (x1) [obs] {$x_1$}; \&
    \node (x2) [obs] {$x_2$}; \&
    \node (x3) [obs] {$x_3$}; \&
    \node (xi) [] {\dots}; \&
    \node (xn) [obs] {$x_n$}; \\
  };
  \draw [-] (fac) -- (x1);
  \draw [-] (fac) -- (x2);
  \draw [-] (fac) -- (x3);
  \draw [-] (fac) -- (xn);
  \draw [-] (fac) -- (xi);
\end{tikzpicture}
\caption{\label{fig:simple-all-dependent}A general factor graph able
         to model any unconditional distribution on the sensed variables
         requires a factor connecting all of them.}
\end{figure}

Nonetheless such an approach suffers from
the \emph{curse of dimensionality}: as the number of sensed features and feature
types increases exponential amounts of data are needed to describe it.
Having interest in avoiding the issues associated with an high-connected factor
an assumption on independent features can be done and then the unconditional
probability can be modelled with a fully disconnected variables, but with
factors that account for existent bias on each single feature (as visible on
graph in \autoref{fig:simple-independent-graph}).

In the case there is only one sensed feature the distribution generated by an
assumption of independent features correctly models the unconditional
probability. And it deviates from it as more features are sensed.
The individual factors associated with each variable can be seen as a scaling of
each feature that tries to account for a possible existent bias on each
of them. Therefore, although far from the desired factor, it is expected to be a
better estimate than assuming a uniform distribution.

\begin{figure}[h]
\centering
\begin{tikzpicture}
  \node [matrix,matrix anchor=mid, column sep=20pt, row sep=10pt,ampersand replacement=\&] {
    \& \& \& \& \\
    \node (f1) [factor] {}; \&
    \node (f2) [factor] {}; \&
    \node (f3) [factor] {}; \&
    \node (fi) [] {\dots}; \&
    \node (fn) [factor] {}; \\
    \node (x1) [obs] {$x_1$}; \&
    \node (x2) [obs] {$x_2$}; \&
    \node (x3) [obs] {$x_3$}; \&
    \node (xi) [] {\dots}; \&
    \node (xn) [obs] {$x_n$}; \\
  };
  \draw [-] (f1) -- (x1);
  \draw [-] (f2) -- (x2);
  \draw [-] (f3) -- (x3);
  \draw [-] (fi);
  \draw [-] (fn) -- (xn);
\end{tikzpicture}
\caption{\label{fig:simple-independent-graph}A factor graph modelling an
         independent distribution over the sensed set of features $x$.}
\end{figure}



\subsection{Threshold Functions}
Three threshold functions were created using the knowledge on the synthetic
distribution and the models learnt from the sample data:
$G$ on \autoref{fig:simple-cond-graph},
$U$ on \autoref{fig:simple-uniform-graph} and
$I$ on \autoref{fig:simple-independent-graph}.

\begin{description}
\item[exact] 
- since the distribution is synthetic there is access to $P(x)$ and $P(x|concept)$
and the ordering function $P(x|\overline{novel})/P(x)$ could be created
to test how far the other presented thresholds are from optimal.


\item[uniform]
- by assuming a uniform unconditional distribution the ordering function is
  given by $P_G(x)/P_U(x)$.

\item[independent]
- using the unlabelled data the unconditional distribution can be approximated.
  In this case, it was approximated with an independent distribution of the
  sensed features. The independent threshold was implemented with $P_G(x)/P_I(x)$.
\end{description}


\subsection{Probability Ratio Comparison}
%%% Results 1
% Show the threshold ratio is an optimal detector (if perfect information was available)
% Show that the thresholds are suitable functions for implementing a static threshold.
As first tryout, the performance of the novelty threshold selection was plotted for a set
of 1000 samples taken out from the whole distribution (\autoref{fig:synthetic-roc}).
Those samples contain different number of sensed properties for each room, mimicking
the dynamic properties expected to see when implemented on a robot.

\begin{figure}[h]
\centering
\includegraphics[width=0.60\textwidth]{results/synthetic-all.pdf}

\caption{\label{fig:synthetic-roc}ROC curve comparing novelty detection performance
         under samples with variable size of sensed properties.}
\end{figure}

The convex shape for the optimal threshold shows that the ratio between conditional
and unconditional probability is indeed an optimal detector and is suitable for
implementing a threshold when the samples are taken from dynamic
distributions (e.g.\ some samples where there is only access to room size versus
samples where there is a lot of information about the room properties).

% Discuss importance on approximating unconditional probability.
Its also possible to see how important it is to estimate a correct unconditional
probability in order to obtain a correct novelty measure on the inputs.
The assumption of a uniform unconditional probability has led to very poor results.
That is probably explained by the semantic properties being highly
biased towards some values. And shows that bias plays an important step
in detecting whether a given sensed value is a valuable cue about the room category.



%%% Results 2
% Measure performance of the thresholds as more information becomes available.
\subsection{Performance Changes With Amount of Available Information}
In order to measure the performance impact as more semantic information becomes
available ROC curves were plotted for samples grouped by the number of sensed
semantic features.

\begin{figure}[h]
\centering

\subfloat[3 sensed features]{\includegraphics[width=0.40\textwidth]{results/synthetic-3features.pdf}}
\qquad
\subfloat[5 sensed features]{\includegraphics[width=0.40\textwidth]{results/synthetic-5features.pdf}}

\subfloat[10 sensed features]{\includegraphics[width=0.40\textwidth]{results/synthetic-10features.pdf}}
\qquad
\subfloat[50 sensed features]{\includegraphics[width=0.40\textwidth]{results/synthetic-50features.pdf}}

\caption{\label{fig:synthetic-roc-breakdown}ROC curves plotted showing performance of the
         presented novelty detection method on graphs generated for different amount of
         sensed features.}
\end{figure}

It is possible to see that as the system gains more semantic information it
becomes easier to detect novelty. The input space size increases and allows the
several existing classes to become more easily distinguished.

The performance of the independent threshold decreases as the number of sensed
features increases. This is easily explained by the fact that the graph $I$ is not
able to model the existent dependence between the features. This becomes obvious
as the number of features increases (e.g.\ graph $I$ perfectly models $P(x)$ in the
case where only 1 feature is sensed).

The uniform threshold shows a poor performance specially on small size samples
where its performs almost no better than random.
It performance increases as the size of sensed features increases but nonetheless
its very small when compared to how optimal a threshold could be.

